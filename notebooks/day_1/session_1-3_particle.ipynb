{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "#### Experimental description\n",
    "- Basic information about the data set can be found here: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification#)\n",
    "- Data is taken from the MiniBooNE experiment at Fermi lab\n",
    "- A beam of neutrinos is fired at a neutrino detector\n",
    "- Beam primarily consists of muon neutrinos\n",
    "- Theory: Neutrinos can oscillate flavor e.g. muon to electron neutrino: $\\nu_{\\mu}\\rightarrow\\nu_{e}$\n",
    "- If MiniBooNE detects an excess of electron neutrinos, the theory is supported\n",
    "- Our task is to train a machine learning model to predict the type of a neutrino based on its detection signature\n",
    "\n",
    "#### Classification problems\n",
    "- Classification tasks consist of N samples, each with K features and M categorizations\n",
    "- For this data set, M = 2\n",
    "    - This is binary classification\n",
    "    - Usually set $M\\epsilon\\{0,1\\}$ (usually interpreted as negative or positive, false or true, noise or signal)\n",
    "- M = 0:\n",
    "    - Muon neutrino detection, which is considered **noise**\n",
    "- M = 1:\n",
    "    - Electron neutrino detection, **signal**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file_path = './data/particle/MiniBooNE_PID.txt'\n",
    "output_file_path = './data/particle/MiniBooNE_PID_cleaned.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_0 = 36499    # Number of electron neutrinos (signal)\n",
    "num_1 = 93565    # Number of muon neutrinos (noise)\n",
    " \n",
    "# Open input file handle & reader\n",
    "with open(input_file_path, 'r') as input_file_handle:\n",
    "    input_reader = csv.reader(input_file_handle, delimiter = ' ')\n",
    "    \n",
    "    # Open output file handle & writer\n",
    "    with open(output_file_path, 'w') as output_file_handle:\n",
    "        output_writer = csv.writer(output_file_handle, delimiter = ' ')\n",
    "        \n",
    "        next(input_reader)    # Skip first line\n",
    "        \n",
    "        # Loop over input file rows\n",
    "        i = 0\n",
    "        for row in input_reader:\n",
    "            \n",
    "            new_row = [ele for ele in row if ele != '']    # Skip the spaces\n",
    "            \n",
    "            \n",
    "            \n",
    "            if i < num_0:\n",
    "                # Electron neutrino\n",
    "                new_row += ['1']\n",
    "            else:\n",
    "                # Muon neutrino\n",
    "                new_row += ['0']\n",
    "            \n",
    "            # Write the fixed row to the new file\n",
    "            output_writer.writerow(new_row)\n",
    "            \n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/particle/MiniBooNE_PID_cleaned.txt'\n",
    "full_data = np.genfromtxt(file_path, delimiter=' ')    # Nifty numpy function to load csv directly into numpy array\n",
    "np.random.shuffle(full_data)    # Scramble the array so we can't cheat :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   4.63185     2.60109    97.0097   ...,    3.11163     0.265011    0.      ]\n",
      " [   4.6394      0.666682   55.845    ...,    2.70267     0.245864    0.      ]\n",
      " [   5.93574     3.08672    51.7441   ...,    3.31021     0.323669    0.      ]\n",
      " ..., \n",
      " [   7.66781     1.92104   124.429    ...,    4.17329     0.219627    0.      ]\n",
      " [   4.81791     1.89325   102.493    ...,    2.6953      0.203304    0.      ]\n",
      " [   6.51519     3.21408    25.0301   ...,    3.22264     0.166939    0.      ]]\n"
     ]
    }
   ],
   "source": [
    "print(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. How many total particle detections are present in the data set?\n",
    "- Assign a new variable N to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130064\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Put solution here! #\n",
    "######################\n",
    "\n",
    "N = full_data.shape[0]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. How many features are in the data set? \n",
    "- Assign a new variable K to this value\n",
    "- Hint: Remember that the full data loaded also includes the classification variables $y$ which should **not** be included in the total variable count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Put solution here! #\n",
    "######################\n",
    "\n",
    "K = full_data.shape[1] - 1\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. How many of the neutrinos are electron flavored (1)? Muon flavored (0)?\n",
    "- Assign new variables N_1 and N_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130064\n"
     ]
    }
   ],
   "source": [
    "print(len(full_data[:,-1] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = len(np.where(full_data[:,-1] == 1)[0])\n",
    "N_0 = len(np.where(full_data[:,-1] == 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97548, 50) (97548,)\n",
      "(32516, 50) (32516,)\n"
     ]
    }
   ],
   "source": [
    "X_train_data = full_data[:int(3/4.*N),:-1]\n",
    "y_train_data = full_data[:int(3/4.*N),-1]\n",
    "\n",
    "print(X_train_data.shape, y_train_data.shape)\n",
    "\n",
    "X_test_data = full_data[int(3/4.*N):,:-1]\n",
    "y_test_data = full_data[int(3/4.*N):,-1]\n",
    "\n",
    "print(X_test_data.shape, y_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89180711034567595"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_data, y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
