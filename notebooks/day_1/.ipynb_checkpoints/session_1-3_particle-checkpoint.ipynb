{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "#### Experimental description\n",
    "- Basic information about the data set can be found here: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification#)\n",
    "- Data is taken from the MiniBooNE experiment at Fermi lab\n",
    "- A beam of neutrinos is fired at a neutrino detector\n",
    "- Beam primarily consists of muon neutrinos\n",
    "- Theory: Neutrinos can oscillate flavor e.g. muon to electron neutrino: $\\nu_{\\mu}\\rightarrow\\nu_{e}$\n",
    "- If MiniBooNE detects an excess of electron neutrinos, the theory is supported\n",
    "- Our task is to train a machine learning model to predict the type of a neutrino based on its detection signature\n",
    "\n",
    "#### Classification problems\n",
    "- Classification tasks consist of N samples, each with K features and M categorizations\n",
    "- For this data set, M = 2\n",
    "    - This is binary classification\n",
    "    - Usually set $M\\epsilon\\{0,1\\}$ (usually interpreted as negative or positive, false or true, noise or signal)\n",
    "- M = 0:\n",
    "    - Muon neutrino detection, which is considered **noise**\n",
    "- M = 1:\n",
    "    - Electron neutrino detection, **signal**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file_path = './data/particle/MiniBooNE_PID.txt'\n",
    "output_file_path = './data/particle/MiniBooNE_PID_cleaned.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_0 = 36499    # Number of electron neutrinos (signal)\n",
    "num_1 = 93565    # Number of muon neutrinos (noise)\n",
    " \n",
    "# Open input file handle & reader\n",
    "with open(input_file_path, 'r') as input_file_handle:\n",
    "    input_reader = csv.reader(input_file_handle, delimiter = ' ')\n",
    "    \n",
    "    # Open output file handle & writer\n",
    "    with open(output_file_path, 'w') as output_file_handle:\n",
    "        output_writer = csv.writer(output_file_handle, delimiter = ' ')\n",
    "        \n",
    "        next(input_reader)    # Skip first line\n",
    "        \n",
    "        i = 0\n",
    "        for row in input_reader:\n",
    "            \n",
    "            new_row = [ele for ele in row if ele != '']\n",
    "            \n",
    "            if i < num_0:\n",
    "                new_row += ['1']\n",
    "            else:\n",
    "                new_row += ['0']\n",
    "            \n",
    "            \n",
    "            output_writer.writerow(new_row)\n",
    "            \n",
    "            i = i + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/particle/MiniBooNE_PID_cleaned.txt'\n",
    "full_data = np.genfromtxt(file_path, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.59413000e+00   4.68803000e-01   2.06916000e+01 ...,   7.17692000e-02\n",
      "    2.45996000e-01   1.00000000e+00]\n",
      " [  3.86388000e+00   6.45781000e-01   1.81375000e+01 ...,   3.33613000e-01\n",
      "    2.30621000e-01   1.00000000e+00]\n",
      " [  3.38584000e+00   1.19714000e+00   3.60807000e+01 ...,   2.55512000e-01\n",
      "    1.80901000e-01   1.00000000e+00]\n",
      " ..., \n",
      " [  3.10842000e+00   2.17814000e+00   5.63651000e+01 ...,   7.30342000e-01\n",
      "    1.52876000e-01   0.00000000e+00]\n",
      " [  5.44560000e+00   1.84570000e+00   1.03463000e+02 ...,   8.19867000e-01\n",
      "    2.10619000e-01   0.00000000e+00]\n",
      " [  4.55062000e+00   1.34174000e+00   8.00887000e+01 ...,   7.42709000e-01\n",
      "    2.76477000e-01   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. How many total particle detections are present in the data set?\n",
    "- Assign a new variable N to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130064\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Put solution here! #\n",
    "######################\n",
    "\n",
    "N = full_data.shape[0]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. How many features are in the data set? \n",
    "- Assign a new variable K to this value\n",
    "- Hint: Remember that the full data loaded also includes the classification variables $y$ which should **not** be included in the total variable count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Put solution here! #\n",
    "######################\n",
    "\n",
    "K = full_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. How many of the neutrinos are electron flavored (1)? Muon flavored (0)?\n",
    "- Assign new variables N_1 and N_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(full_data[:,-1]==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([     0,      1,      2, ..., 130061, 130062, 130063]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(full_data[:,-1] == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many total particle detections are present in the data set?\n",
    "\n",
    "### 2. How many features are in the data set?\n",
    "\n",
    "### 3. How many of the particles are signal (1)? How many are noise (0)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130064, 51)\n"
     ]
    }
   ],
   "source": [
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_length(file_handle, file_reader):\n",
    "    file_handle.seek(0)\n",
    "    length = sum(1 for row in file_reader)\n",
    "    file_handle.seek(0)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eebed8c9e217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "file_path = './data/particle/MiniBooNE_PID.txt'\n",
    "with open(file_path, 'r') as file_handle:\n",
    "        \n",
    "    file_reader = csv.reader(file_handle, delimiter = ' ')\n",
    "    \n",
    "    length = get_csv_length(file_handle, file_reader)\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(next(reader))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dialect', 'DictReader', 'DictWriter', 'Error', 'OrderedDict', 'QUOTE_ALL', 'QUOTE_MINIMAL', 'QUOTE_NONE', 'QUOTE_NONNUMERIC', 'Sniffer', 'StringIO', '_Dialect', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__version__', 'excel', 'excel_tab', 'field_size_limit', 'get_dialect', 'list_dialects', 're', 'reader', 'register_dialect', 'unix_dialect', 'unregister_dialect', 'writer']\n"
     ]
    }
   ],
   "source": [
    "print(dir(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
